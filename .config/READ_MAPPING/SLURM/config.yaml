# -------------- ReadMapping (PE) profile for SLURM job schedulers -------------- #


# --------------------------------------------------------------------------------- #
## ADAPT THE FOLLOWING CLUSTER PARAMETERS TO FIT YOUR WORKING ENVIRONMENT AND DATA ##
# --------------------------------------------------------------------------------- #

## Provide here the default resources ('partition' and/or 'mem_mb') for all the steps
# The 'mem_mb' value should be an integer (representing an amount of megabytes = Mb of RAM) and will be passed to the --mem-per-cpu sbatch option when submitting jobs
default-resources:
  - mem_mb=5000
  - partition=agap_normal


## Set resources ('partition' and/or 'mem_mb') for specific steps
set-resources:
  - Mapping_PairedEndFastqs:mem_mb=5000
  - Mapping_SingleEndFastqs:mem_mb=10000
  - Mapping_SingleEndFastqs:partition=agap_bigmem
  - Remapping_PairedEndExtractedFastqs:mem_mb=5000
  - Remapping_SingleEndExtractedFastqs:mem_mb=10000
  - Remapping_SingleEndExtractedFastqs:partition=agap_bigmem



## Set a number of threads for specific steps (if not specified, default = 1)
# This number will be passed to the --cpus-per-task sbatch option when submitting jobs
set-threads:
  - Mapping_PairedEndFastqs=8
  - Mapping_SingleEndFastqs=8
  - Remapping_PairedEndExtractedFastqs=8
  - Remapping_SingleEndExtractedFastqs=8







# ---------------------------------------------------- #
## YOU DO NOT NEED TO MODIFY ANYTHING BELOW THIS LINE ##
# ---------------------------------------------------- #

cluster:
  mkdir -p Logs_ReadMappingWorkflow &&
  WILDCARDS_NAMES=$(echo {wildcards} | awk -F "=|," '{{WC=""; for (i=2; i<=NF; i+=2) {{WC=WC"_"$i}}; print WC}}') &&
  sbatch
  --partition={resources.partition}
  --cpus-per-task={threads}
  --mem-per-cpu={resources.mem_mb}M
  --job-name=RM.{rule}
  --output=Logs_ReadMappingWorkflow/{rule}${{WILDCARDS_NAMES}}.%j.log


latency-wait: 20
jobs: 1